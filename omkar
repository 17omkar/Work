9import pandas as pd
import datetime
import random

class RecData2MLData:

    def __init__(self):
        self.data = pd.DataFrame(columns=["batch number", "branch code", "account code", "date difference", "tran code", "field number", "operator id", "operator name", "target"])

    def filehandle(self, st1, st2):
        with open(st1, "r") as file1, open(st2, "r") as file2:
            lines1 = file1.readlines()[:120000]  # Read first 120000 lines from non-fraudulent file
            lines2 = file2.readlines()  # Read all lines from fraudulent file

            for line in lines1:
                self.process_line(line, target=0)

            for line in lines2:
                self.process_line(line, target=1)

        # Shuffle the combined data
        self.data = self.data.sample(frac=1).reset_index(drop=True)

    def process_line(self, string, target):
        str_len = len(string)

        rec_type = int(string[0:1]) # 1
        bank_code = int(string[1:4]) # 2
        branch_code = int(string[4:7]) # 3
        acct_code = int(string[14:18]) # 4
        acct_type = int(string[18:19]) # 5
        class_code = int(string[19:21]) # 6
        collateral_code = int(string[21:25]) # 7

        post_date = datetime.date(2024, int(string[47:49]), int(string[49:51]))
        effective_date = datetime.date(2024, int(string[40:42]), int(string[42:44]))
        diff_date = (post_date - effective_date).days

        tran_code = int(string[54:56]) # 9
        field_number = int(string[56:59].strip()) if string[56:59].strip() else None

        opid = string[97:105].strip()
        if len(opid) != 8 or not opid[0].isalpha() or not opid[1:].isalnum():
            opid = None

        opname = string[105:121].strip() if string[105:121].strip() else None
        batch_num = int(string[121:124])

        newrow = {
            "batch number": batch_num,
            "branch code": branch_code,
            "account code": acct_code,
            "date difference": diff_date,
            "tran code": tran_code,
            "field number": field_number,
            "operator id": opid,
            "operator name": opname,
            "target": target
        }

        self.data = self.data.append(newrow, ignore_index=True)

if __name__ == "__main__":
    # Paths to the files
    non_fraudulent_file_path = "non_fraud_data.txt"
    fraudulent_file_path = "fraud_data.txt"

    # Create an instance of the class and process the files
    rec_data_ml = RecData2MLData()
    rec_data_ml.filehandle(non_fraudulent_file_path, fraudulent_file_path)

    # The resulting DataFrame with combined and shuffled data
    print(rec_data_ml.data)
    # Optionally save the DataFrame to a CSV file
    rec_data_ml.data.to_csv("combined_data.csv", index=False)














import pandas as pd
import datetime

class RecData2MLData:

    def __init__(self):
        self.data = pd.DataFrame()

    def filehandle(self, st1, st2):
        # Open the non-fraudulent and fraudulent data files
        with open(st1, "r") as file1, open(st2, "r") as file2:
            lines1 = file1.readlines()[:120000]  # Read first 120000 lines from non-fraudulent file
            lines2 = file2.readlines()  # Read all lines from fraudulent file

            # Process non-fraudulent lines
            non_fraud_data = [self.process_line(line, target=0) for line in lines1]

            # Process fraudulent lines
            fraud_data = [self.process_line(line, target=1) for line in lines2]

        # Concatenate the data into a single DataFrame
        self.data = pd.concat([non_fraud_data, fraud_data], ignore_index=True)

        # Shuffle the DataFrame
        self.data = self.data.sample(frac=1).reset_index(drop=True)

    def process_line(self, string, target):
        str_len = len(string)

        # Extract relevant fields from the string
        rec_type = int(string[0:1]) # Record Type
        bank_code = int(string[1:4]) # Bank Code
        branch_code = int(string[4:7]) # Branch Code
        acct_code = int(string[14:18]) # Account Code
        acct_type = int(string[18:19]) # Account Type
        class_code = int(string[19:21]) # Class Code
        collateral_code = int(string[21:25]) # Collateral Code

        # Calculate date difference
        post_date = datetime.date(2024, int(string[47:49]), int(string[49:51]))
        effective_date = datetime.date(2024, int(string[40:42]), int(string[42:44]))
        diff_date = (post_date - effective_date).days

        tran_code = int(string[54:56]) # Transaction Code
        field_number = int(string[56:59].strip()) if string[56:59].strip() else None

        # Validate and extract operator ID
        opid = string[97:105].strip()
        if len(opid) != 8 or not opid[0].isalpha() or not opid[1:].isalnum():
            opid = None

        # Extract operator name
        opname = string[105:121].strip() if string[105:121].strip() else None

        # Extract batch number
        batch_num = int(string[121:124])

        # Return a dictionary with the extracted data and target label
        return {
            "batch number": batch_num,
            "branch code": branch_code,
            "account code": acct_code,
            "date difference": diff_date,
            "tran code": tran_code,
            "field number": field_number,
            "operator id": opid,
            "operator name": opname,
            "target": target
        }

if __name__ == "__main__":
    # Paths to the files containing non-fraudulent and fraudulent data
    non_fraudulent_file_path = "non_fraud_data.txt"
    fraudulent_file_path = "fraud_data.txt"

    # Create an instance of the class and process the files
    rec_data_ml = RecData2MLData()
    rec_data_ml.filehandle(non_fraudulent_file_path, fraudulent_file_path)

    # The resulting DataFrame with combined and shuffled data
    print(rec_data_ml.data)
    # Optionally save the DataFrame to a CSV file
    rec_data_ml.data.to_csv("combined_data.csv", index=False)






import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import joblib

# Function to load and preprocess data from CSV
def load_and_preprocess_data(csv_file):
    # Load data from CSV file
    df = pd.read_csv(csv_file)

    # Encode categorical variables
    label_encoder = LabelEncoder()
    df['operator id'] = label_encoder.fit_transform(df['operator id'].astype(str))
    df['operator name'] = label_encoder.fit_transform(df['operator name'].astype(str))

    # Split data into features and target
    X = df.drop(columns=['target'])
    y = df['target']

    # Normalize the data
    scaler = StandardScaler()
    X = scaler.fit_transform(X)
    
    return X, y, scaler

# Main function to train and evaluate the model
def train_and_evaluate_model(csv_file):
    # Load and preprocess data
    X, y, scaler = load_and_preprocess_data(csv_file)

    # Split into training and testing data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Build the Random Forest model
    model = RandomForestClassifier(n_estimators=100, random_state=42)

    # Train the model
    model.fit(X_train, y_train)

    # Make predictions
    y_pred = model.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    print(f'Test accuracy: {accuracy:.4f}')
    print(classification_report(y_test, y_pred))

    # Save the model and scaler
    joblib.dump(model, 'fraud_detection_rf_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')

    return model, scaler

# Function to make predictions using the trained model
def make_predictions(csv_file, model_file, scaler_file):
    # Load the model and scaler
    model = joblib.load(model_file)
    scaler = joblib.load(scaler_file)

    # Load and preprocess data
    df = pd.read_csv(csv_file)
    X = df.drop(columns=['target'])

    # Encode categorical variables
    label_encoder = LabelEncoder()
    X['operator id'] = label_encoder.fit_transform(X['operator id'].astype(str))
    X['operator name'] = label_encoder.fit_transform(X['operator name'].astype(str))

    # Normalize the data
    X = scaler.transform(X)

    # Make predictions
    predictions = model.predict(X)

    # Add predictions to DataFrame
    df['predictions'] = predictions

    return df

if __name__ == "__main__":
    # Path to the CSV file containing the data
    csv_file_path = "combined_data.csv"

    # Train and evaluate the model
    train_and_evaluate_model(csv_file_path)

    # Make predictions on the same data
    predictions_df = make_predictions(csv_file_path, 'fraud_detection_rf_model.pkl', 'scaler.pkl')

    # Print the predictions
    print(predictions_df.head())
    # Optionally save the predictions to a CSV file
    predictions_df.to_csv("predictions.csv", index=False)
